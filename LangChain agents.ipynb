{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca277e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\".env\") as f:\n",
    "    for line in f:\n",
    "        # Ignore comments and empty lines\n",
    "        if line.strip() and not line.startswith(\"#\"):\n",
    "            key, value = line.strip().split(\"=\", 1)\n",
    "            os.environ[key] = value\n",
    "            \n",
    "api_key = os.environ.get('API_KEY')\n",
    "api_key = api_key.strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd78c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.tools.arxiv.tool import ArxivQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331116fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.tools as lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d1117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = ArxivQueryRun()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"papers\",\n",
    "        func=papers.run,\n",
    "        description=\"useful for when you need to answer about research paper\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366a741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best as you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658e9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0, openai_api_key=api_key), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ca07c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should look for recent research papers on this topic.\n",
      "Action: papers\n",
      "Action Input: Retrieval Augmented Generation\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2022-02-13\n",
      "Title: A Survey on Retrieval-Augmented Text Generation\n",
      "Authors: Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu\n",
      "Summary: Recently, retrieval-augmented text generation attracted increasing attention\n",
      "of the computational linguistics community. Compared with conventional\n",
      "generation models, retrieval-augmented text generation has remarkable\n",
      "advantages and particularly has achieved state-of-the-art performance in many\n",
      "NLP tasks. This paper aims to conduct a survey about retrieval-augmented text\n",
      "generation. It firstly highlights the generic paradigm of retrieval-augmented\n",
      "generation, and then it reviews notable approaches according to different tasks\n",
      "including dialogue response generation, machine translation, and other\n",
      "generation tasks. Finally, it points out some important directions on top of\n",
      "recent methods to facilitate future research.\n",
      "\n",
      "Published: 2023-08-08\n",
      "Title: Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance\n",
      "Authors: Xuchao Zhang, Menglin Xia, Camille Couturier, Guoqing Zheng, Saravan Rajmohan, Victor Ruhle\n",
      "Summary: Retrieval augmented models show promise in enhancing traditional language\n",
      "models by improving their contextual understanding, integrating private data,\n",
      "and reducing hallucination. However, the processing time required for retrieval\n",
      "augmented large language models poses a challenge when applying them to tasks\n",
      "that require real-time responses, such as composition assistance.\n",
      "  To overcome this limitation, we propose the Hybrid Retrieval-Augmented\n",
      "Generation (HybridRAG) framework that leverages a hybrid setting that combines\n",
      "both client and cloud models. HybridRAG incorporates retrieval-augmented memory\n",
      "generated asynchronously by a Large Language Model (LLM) in the cloud. By\n",
      "integrating this retrieval augmented memory, the client model acquires the\n",
      "capability to generate highly effective responses, benefiting from the LLM's\n",
      "capabilities. Furthermore, through asynchronous memory integration, the client\n",
      "model is capable of delivering real-time responses to user requests without the\n",
      "need to wait for memory synchronization from the cloud. Our experiments on\n",
      "Wikitext and Pile subsets show that HybridRAG achieves lower latency than a\n",
      "cloud-based retrieval-augmented LLM, while outperforming client-only models in\n",
      "utility.\n",
      "\n",
      "Published: 2023-05-27\n",
      "Title: Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In\n",
      "Authors: Zichun Yu, Chenyan Xiong, Shi Yu, Zhiyuan Liu\n",
      "Summary: Retrieval augmentation can aid language models (LMs) in knowledge-intensive\n",
      "tasks by supplying them with external information. Prior works on retrieval\n",
      "augmentation usually jointly fine-tune the retriever and the LM, making them\n",
      "closely coupled. In this paper, we explore the scheme of generic retrieval\n",
      "plug-in: the retriever is to assist target LMs that may not be known beforehand\n",
      "or are unable to be fine-tuned together. To retrieve useful documents for\n",
      "unseen target LMs, we propose augmentation-adapted retriever (AAR), which\n",
      "learns LM's preferences obtained from a known source LM. Experiments on the\n",
      "MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM\n",
      "is able to significantly improve the zero-shot generalization of larger target\n",
      "LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates\n",
      "that the preferences of different LMs overlap, enabling AAR trained with a\n",
      "single source LM to serve as a generic plug-in for various target LMs. Our code\n",
      "is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the recent development regarding Retrieval Augmented Generation.\n",
      "Final Answer: Recent research papers have highlighted the generic paradigm of retrieval-augmented generation, and have reviewed notable approaches according to different tasks including dialogue response generation, machine translation, and other generation tasks. Hybrid Retrieval-Augmented Generation (HybridRAG) has been proposed to leverage a hybrid setting that combines both client and cloud models, and Augmentation-Adapted Retriever (AAR) has been proposed to learn language model's preferences obtained from a known source language model.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Recent research papers have highlighted the generic paradigm of retrieval-augmented generation, and have reviewed notable approaches according to different tasks including dialogue response generation, machine translation, and other generation tasks. Hybrid Retrieval-Augmented Generation (HybridRAG) has been proposed to leverage a hybrid setting that combines both client and cloud models, and Augmentation-Adapted Retriever (AAR) has been proposed to learn language model's preferences obtained from a known source language model.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Tell me about the recent development regarding Retrieval Augmented Generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478a25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
